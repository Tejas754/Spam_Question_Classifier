{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fc39091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.14.0-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.14.0\n",
      "  Downloading tensorflow_intel-2.14.0-cp310-cp310-win_amd64.whl (284.1 MB)\n",
      "     -------------------------------------- 284.1/284.1 MB 1.9 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.15,>=2.14.0\n",
      "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "     ------------------------------------- 440.7/440.7 kB 13.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.59.0-cp310-cp310-win_amd64.whl (3.7 MB)\n",
      "     ---------------------------------------- 3.7/3.7 MB 16.7 MB/s eta 0:00:00\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.23.5)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.7.0)\n",
      "Collecting ml-dtypes==0.2.0\n",
      "  Using cached ml_dtypes-0.2.0-cp310-cp310-win_amd64.whl (938 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.24.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.8.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (22.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting keras<2.15,>=2.14.0\n",
      "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 15.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (65.6.3)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "     -------------------------------------- 130.2/130.2 kB 7.5 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.15,>=2.14\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 14.1 MB/s eta 0:00:00\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "     --------------------------------------- 24.4/24.4 MB 14.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.23.3-py2.py3-none-any.whl (182 kB)\n",
      "     ------------------------------------- 182.3/182.3 kB 11.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.28.1)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.1)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, opt-einsum, oauthlib, ml-dtypes, keras, grpcio, google-pasta, gast, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.23.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.59.0 keras-2.14.0 libclang-16.0.6 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.14.1 tensorboard-data-server-0.7.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-intel-2.14.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.14.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59810298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from nltk import word_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense, Dropout, LSTM, Bidirectional, Input, Activation\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24b6ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af074de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9415b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1306122 entries, 0 to 1306121\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   qid            1306122 non-null  object\n",
      " 1   question_text  1306122 non-null  object\n",
      " 2   target         1306122 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 29.9+ MB\n"
     ]
    }
   ],
   "source": [
    "d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a05c87a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_token = Tokenizer(num_words = 50000, char_level=False, split = ' ')\n",
    "keras_token.fit_on_texts(d['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52abcde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222161"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keras_token.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d039adcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,     6,     1,  8333],\n",
       "       [    0,     0,     0, ...,    10,    44,  1846],\n",
       "       [    0,     0,     0, ...,   374,   451,  5546],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  7760, 11663,  2984],\n",
       "       [    0,     0,     0, ...,    43,  3384,   422],\n",
       "       [    0,     0,     0, ...,    10,     4, 21972]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = keras_token.texts_to_sequences(d['question_text'])\n",
    "max_len = 50\n",
    "seq_matrix = sequence.pad_sequences(seq, maxlen=max_len)\n",
    "seq_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe135716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "word2vec = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c6a2919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "709f87fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(word2vec.index_to_key)\n",
    "vocabulary_size = len(words)\n",
    "embedding_dim = len(word2vec['house'])\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulary_size, embedding_dim))\n",
    "for word, i in keras_token.word_index.items():\n",
    "    if word in word2vec:\n",
    "        embedding_matrix[i] = word2vec[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "579f4b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = d['target']\n",
    "y = np.array(y)\n",
    "X = seq_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "056cee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e44520ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 300)           900000000 \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 300)               0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               77056     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 900120833 (-694483964.00 Byte)\n",
      "Trainable params: 120833 (472.00 KB)\n",
      "Non-trainable params: 900000000 (-694967296.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\layer_utils.py:146: RuntimeWarning: overflow encountered in long_scalars\n",
      "  total_memory_size += weight_shape * per_param_size\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocabulary_size, \n",
    "                    output_dim=embedding_dim, input_length=50, \n",
    "                    weights=[embedding_matrix], trainable=False))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49abccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam' ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbe2f5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "22858/22858 [==============================] - 242s 10ms/step - loss: 0.1343 - accuracy: 0.9489 - val_loss: 0.1288 - val_accuracy: 0.9507\n",
      "Epoch 2/30\n",
      "22858/22858 [==============================] - 244s 11ms/step - loss: 0.1256 - accuracy: 0.9510 - val_loss: 0.1228 - val_accuracy: 0.9518\n",
      "Epoch 3/30\n",
      "22858/22858 [==============================] - 248s 11ms/step - loss: 0.1229 - accuracy: 0.9520 - val_loss: 0.1240 - val_accuracy: 0.9524\n",
      "Epoch 4/30\n",
      "22858/22858 [==============================] - 220s 10ms/step - loss: 0.1211 - accuracy: 0.9527 - val_loss: 0.1215 - val_accuracy: 0.9526\n",
      "Epoch 5/30\n",
      "22858/22858 [==============================] - 251s 11ms/step - loss: 0.1199 - accuracy: 0.9531 - val_loss: 0.1191 - val_accuracy: 0.9528\n",
      "Epoch 6/30\n",
      "22858/22858 [==============================] - 248s 11ms/step - loss: 0.1186 - accuracy: 0.9536 - val_loss: 0.1186 - val_accuracy: 0.9529\n",
      "Epoch 7/30\n",
      "22858/22858 [==============================] - 232s 10ms/step - loss: 0.1175 - accuracy: 0.9540 - val_loss: 0.1195 - val_accuracy: 0.9531\n",
      "Epoch 8/30\n",
      "22858/22858 [==============================] - 227s 10ms/step - loss: 0.1167 - accuracy: 0.9544 - val_loss: 0.1204 - val_accuracy: 0.9512\n",
      "Epoch 9/30\n",
      "22858/22858 [==============================] - 230s 10ms/step - loss: 0.1157 - accuracy: 0.9547 - val_loss: 0.1191 - val_accuracy: 0.9531\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "history = model.fit(X_train, y_train, epochs=num_epochs, \n",
    "                    validation_data=(X_validation, y_validation),callbacks =[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d3b99ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12245/12245 [==============================] - 55s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "threshold = 0.5\n",
    "binary_predictions = (pred >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bde2b5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>391837.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.062242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.158490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.017424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.977440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "count  391837.000000\n",
       "mean        0.062242\n",
       "std         0.158490\n",
       "min         0.000000\n",
       "25%         0.000074\n",
       "50%         0.001408\n",
       "75%         0.017424\n",
       "max         0.977440"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pd.DataFrame(pred)\n",
    "pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "486c42ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[362095   5878]\n",
      " [ 11516  12348]]\n",
      "Precision: 0.6774936903324921\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test, binary_predictions)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "true_positives = confusion[1, 1]\n",
    "false_positives = confusion[0, 1]\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "\n",
    "print(\"Precision:\", precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
